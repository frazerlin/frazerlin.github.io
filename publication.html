<!doctype html>
<html lang="en">

	
<head>
    <title>Zheng Lin</title>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="shortcut icon" href="./material/image/favicon.ico" type="image/x-icon" />
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="./css/bootstrap.min.css">
	<link rel="stylesheet" href="./css/lz.css">
</head>

	
<body>
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
        <div class="container">
			<a class="nav-head" href="index.html">Home</a>
            <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive"
             aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav ml-auto">
                    <li class="nav-item">
                        <a class="nav-link nav-diy" href="./publication.html">Publication
                            <span class="sr-only">(current)</span>
                        </a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="./group.html">Group
                            <span class="sr-only">(current)</span>
                        </a>
                    </li>
					<li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                        Course
                    </a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                        <a class="dropdown-item" href="./academic_guide.html">Academic Guide</a>
                    </div>
                	</li>
                </ul>
            </div>
        </div>
    </nav>

    <div class="container">

        <!-- Publications -->
        <section class="row mt-3"> 
			<div class="col-md-12">
				<h2 class="text-center mt-4 mb-4">Publications </h2>
				<!--<p class="text-center"> (*) Equal contribution; (#) Corresponding author; (IF/SCI/JCR) The value correspond to the publication year </p>-->
				
				<!-- 24_ICME_SAQ -->
				<div class="row paper-item" id="24_ICME_SAQ">
					<div class="col-md-3 paper-cover">
						<img src="./material/paper/24_ICME_SAQ_Cover.jpg" class="img-responsive img-thumbnail"/>
					</div>
					<div class="col-md-9 paper-info">
						<span class="paper-title">
							No-Reference Segmentation Annotation Quality Assessment
						</span>
						<br />
						<span class="paper-author">
							<strong class="text-info">Zheng Lin</strong>, Zheng-Peng Duan, Xuying Zhang, Luojun Lin 
					  	</span>
						<br />
						<span class="paper-publication">IEEE International Conference on Multimedia and Expo (ICME), 2024</span>  
						<br />
						<span class="paper-publication">
							[CCF-B Conference, Acceptance Rate=TBD, <span class="paper-highlight">Oral</span>]
						</span>
						<br />
						<a href="#" target="_blank">[PDF]</a> <!-- TO CHANGE -->
						<a href="https://github.com/frazerlin/SAQ" target="_blank">[Code]</a>
						[BibTeX] <!-- TO ADD -->
						[Official] <!-- TO ADD -->
					</div>
				</div>	
				
				<!-- 24_ICME_SlowFast -->
				<div class="row paper-item" id="24_ICME_SlowFast">
					<div class="col-md-3 paper-cover">
						<img src="./material/paper/24_ICME_SlowFast_Cover.jpg" class="img-responsive img-thumbnail"/>
					</div>
					<div class="col-md-9 paper-info">
						<span class="paper-title">
							Slow-Fast Adaptation for Source-Free Object Detection
						</span>
						<br />
						<span class="paper-author">
							Luojun Lin, Qipeng Liu, Xiangwei Zheng, <strong class="text-info">Zheng Lin#</strong>
					  	</span>
						<br />
						<span class="paper-publication">IEEE International Conference on Multimedia and Expo (ICME), 2024</span>  
						<br />
						<span class="paper-publication">[CCF-B Conference, Acceptance Rate=TBD]</span>
						<br />
						<a href="#" target="_blank">[PDF]</a> <!-- TO CHANGE -->
						<a href="#" target="_blank">[Code]</a>
						[BibTeX] <!-- TO ADD -->
						[Official] <!-- TO ADD -->
					</div>
				</div>
				
				<!-- 24_CVPR_TeMO -->
				<div class="row paper-item" id="24_CVPR_TeMO">
					<div class="col-md-3 paper-cover">
						<img src="./material/paper/24_CVPR_TeMO_Cover.jpg" class="img-responsive img-thumbnail"/>
					</div>
					<div class="col-md-9 paper-info">
						<span class="paper-title">
							TeMO: Towards Text-Driven 3D Stylization for Multi-Object Meshes
						</span>
						<br />
						<span class="paper-author">
							Xuying Zhang, Bo-Wen Yin, Yuming Chen, <strong class="text-info">Zheng Lin</strong>, Yunheng Li, Qibin Hou, Ming-Ming Cheng
					  	</span>
						<br />
						<span class="paper-publication">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024</span>  
						<br />
						<span class="paper-publication">[CCF-A Conference, Acceptance Rate=23.6%]</span>
						<br />
						<a href="https://arxiv.org/pdf/2312.04248" target="_blank">[PDF]</a> <!-- TO CHANGE -->
						<a href="https://github.com/zhangxuying1004/TeMO" target="_blank">[Code]</a>
						[BibTeX] <!-- TO ADD -->
						[Official] <!-- TO ADD -->
						<!--<a href="TBD" target="_blank">[中译版]</a>-->
					</div>
				</div>
				
				<!-- 23_CVMJ_SIIS -->
				<div class="row paper-item" id="23_CVMJ_SIIS">
					<div class="col-md-3 paper-cover">
						<img src="./material/paper/23_CVMJ_SIIS_Cover.jpg" class="img-responsive img-thumbnail"/>
					</div>
					<div class="col-md-9 paper-info">
						<span class="paper-title">
							Sequential Interactive Image Segmentation
						</span>
						<br />
						<span class="paper-author">
							<strong class="text-info">Zheng Lin</strong>, Zhao Zhang, Ziyue Zhu, Deng-Ping Fan, Xia-Lei Liu
					  	</span>
						<br />
						<span class="paper-publication">Computational Visual Media (CVMJ), 2023</span>  
						<br />
						<span class="paper-publication">[JCR-1 Journal, IF=17.3, <a href="https://eval.cnki.net/News/ItemDetail?ID=093755b184f6483cb441305f368fc814">中国最具国际影响力学术期刊</a>]</span> <!-- IF is TBD -->
						<br />
						<a href="https://link.springer.com/content/pdf/10.1007/s41095-022-0302-8.pdf" target="_blank">[PDF]</a>
						<a href="#" target="_blank">[Code]</a>
						<a href="./material/paper/23_CVMJ_SIIS_BibTeX.txt" target="_blank">[BibTeX]</a>
						<a href="https://link.springer.com/article/10.1007/s41095-022-0302-8" target="_blank">[Official]</a>
						<a href="https://dengpingfan.github.io/papers/[2022][CVMJ]SIIS_Chinese.pdf" target="_blank">[中译版]</a>
					</div>
				</div>
				
				<!-- 23_TPAMI_CoRP -->
				<div class="row paper-item" id="23_TPAMI_CoRP">
					<div class="col-md-3 paper-cover">
						<img src="./material/paper/23_TPAMI_CoRP_Cover.jpg" class="img-responsive img-thumbnail"/>
					</div>
					<div class="col-md-9 paper-info">
						<span class="paper-title">
							Co-Salient Object Detection With Co-Representation Purification
						</span>
						<br />
						<span class="paper-author">
							Ziyue Zhu, Zhao Zhang, <strong class="text-info">Zheng Lin</strong>, Xing Sun, Ming-Ming Cheng
					  	</span>
						<br />
						<span class="paper-publication">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2023</span>  
						<br />
						<span class="paper-publication">[CCF-A/SCI-1 Journal, IF=23.6]</span> <!-- IF is TBD -->
						<br />
						<a href="https://arxiv.org/pdf/2303.07670" target="_blank">[PDF]</a>
						<a href="https://github.com/ZZY816/CoRP" target="_blank">[Code]</a>
						<a href="./material/paper/23_TPAMI_CoRP_BibTeX.txt" target="_blank">[BibTeX]</a>
						<a href="https://ieeexplore.ieee.org/document/10008072" target="_blank">[Official]</a>
						<a href="https://mftp.mmcheng.net/Papers/23PAMI_CoSal-cn.pdf" target="_blank">[中译版]</a>
					</div>
				</div>		
				
				<!-- 22_CVPR_FocusCut -->
				<div class="row paper-item" id="22_CVPR_FocusCut">
					<div class="col-md-3 paper-cover">
						<img src="./material/paper/22_CVPR_FocusCut_Cover.jpg" class="img-responsive img-thumbnail"/>
					</div>
					<div class="col-md-9 paper-info">
						<span class="paper-title">
							FocusCut: Diving into a Focus View in Interactive Segmentation
						</span>
						<br />
						<span class="paper-author">
							<strong class="text-info">Zheng Lin</strong>, Zheng-Peng Duan, Zhao Zhang, Chun-Le Guo, Ming-Ming Cheng
					  	</span>
						<br />
						<span class="paper-publication">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022</span>  
						<br />
						<span class="paper-publication">
							[CCF-A Conference, Acceptance Rate=4.2%, <span class="paper-highlight">Oral</span>]
						</span>
						<br />
						<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_FocusCut_Diving_Into_a_Focus_View_in_Interactive_Segmentation_CVPR_2022_paper.pdf" target="_blank">[PDF]</a>
						<a href="https://github.com/frazerlin/focuscut" target="_blank">[Code]</a>
						<a href="./material/paper/22_CVPR_FocusCut_BibTeX.txt" target="_blank">[BibTeX]</a>
						<a href="https://ieeexplore.ieee.org/document/9879992" target="_blank">[Official]</a>
						<a href="https://mftp.mmcheng.net/Papers/22CVPR_FocusCut_CN.pdf" target="_blank">[中译版]</a>
					</div>
				</div>
				
				<!-- 22_ACMMM_KnifeCut -->
				<div class="row paper-item" id="22_ACMMM_KnifeCut">
					<div class="col-md-3 paper-cover">
						<img src="./material/paper/22_ACMMM_KnifeCut_Cover.jpg" class="img-responsive img-thumbnail"/>
					</div>
					<div class="col-md-9 paper-info">
						<span class="paper-title">
							KnifeCut: Refining Thin Part Segmentation with Cutting Lines
						</span>
						<br />
						<span class="paper-author">
							<strong class="text-info">Zheng Lin</strong>, Zheng-Peng Duan#, Zhao Zhang, Chun-Le Guo, Ming-Ming Cheng
					  	</span>
						<br />
						<span class="paper-publication">ACM International Conference on Multimedia (ACMMM), 2022</span>  
						<br />
						<span class="paper-publication">
							[CCF-A Conference, Acceptance Rate=5.5%, <span class="paper-highlight">Oral</span>]
						</span>
						<br />
						<a href="https://dl.acm.org/doi/pdf/10.1145/3503161.3547803" target="_blank">[PDF]</a>
						<a href="#" target="_blank">[Code]</a>
						<a href="./material/paper/22_ACMMM_KnifeCut_BibTeX.txt" target="_blank">[BibTeX]</a>
						<a href="https://dl.acm.org/doi/10.1145/3503161.3547803" target="_blank">[Official]</a>
						<a href="https://mftp.mmcheng.net/Papers/22ACMMM_KnifeCut_CN.pdf" target="_blank">[中译版]</a>
					</div>
				</div>		
				
				<!-- 22_ACMMM_MMIIS -->
				<div class="row paper-item" id="22_ACMMM_MMIIS">
					<div class="col-md-3 paper-cover">
						<img src="./material/paper/22_ACMMM_MMIIS_Cover.jpg" class="img-responsive img-thumbnail"/>
					</div>
					<div class="col-md-9 paper-info">
						<span class="paper-title">
							Multi-Mode Interactive Image Segmentation
						</span>
						<br />
						<span class="paper-author">
							<strong class="text-info">Zheng Lin</strong>, Zhao Zhang, Ling-Hao Han, Shao-Ping Lu
					  	</span>
						<br />
						<span class="paper-publication">ACM International Conference on Multimedia (ACMMM), 2022</span>  
						<br />
						<span class="paper-publication">[CCF-A Conference, Acceptance Rate=27.9%]</span>
						<br />
						<a href="https://dl.acm.org/doi/pdf/10.1145/3503161.3548096" target="_blank">[PDF]</a>
						<a href="#" target="_blank">[Code]</a>
						<a href="./material/paper/22_ACMMM_MMIIS_BibTeX.txt" target="_blank">[BibTeX]</a>
						<a href="https://dl.acm.org/doi/10.1145/3503161.3548096" target="_blank">[Official]</a>
						<a href="./material/paper/22_ACMMM_MMIIS_Paper_CN.pdf" target="_blank">[中译版]</a>
					</div>
				</div>	
				
				<!-- 22_TPAMI_SalSem -->
				<div class="row paper-item" id="22_TPAMI_SalSem">
					<div class="col-md-3 paper-cover">
						<img src="./material/paper/22_TPAMI_SalSem_Cover.jpg" class="img-responsive img-thumbnail"/>
					</div>
					<div class="col-md-9 paper-info">
						<span class="paper-title">
							A Highly Efficient Model to Study the Semantics of Salient Object Detection
						</span>
						<br />
						<span class="paper-author">
							Ming-Ming Cheng, Shang-Hua Gao, Ali Borji, Yong-Qiang Tan, <strong class="text-info">Zheng Lin</strong>, Meng Wang
					  	</span>
						<br />
						<span class="paper-publication">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2022</span>  
						<br />
						<span class="paper-publication">[CCF-A/SCI-1 Journal, IF=23.6]</span>
						<br />
						<a href="https://mftp.mmcheng.net/Papers/21PAMI-Sal100K.pdf" target="_blank">[PDF]</a>
						<a href="https://github.com/ShangHua-Gao/SOD100K" target="_blank">[Code]</a>
						<a href="./material/paper/22_TPAMI_SalSem_BibTeX.txt" target="_blank">[BibTeX]</a>
						<a href="https://ieeexplore.ieee.org/document/9523773" target="_blank">[Official]</a>
						<a href="https://mftp.mmcheng.net/Papers/21PAMI-sal100k_cn.pdf" target="_blank">[中译版]</a>
					</div>
				</div>			
				
				<!-- 22_TPAMI_CoEGNet -->
				<div class="row paper-item" id="22_TPAMI_CoEGNet">
					<div class="col-md-3 paper-cover">
						<img src="./material/paper/22_TPAMI_CoEGNet_Cover.jpg" class="img-responsive img-thumbnail"/>
					</div>
					<div class="col-md-9 paper-info">
						<span class="paper-title">
							Re-thinking Co-Salient Object Detection
						</span>
						<br />
						<span class="paper-author">
							Deng-Ping Fan, Tengpeng Li, <strong class="text-info">Zheng Lin</strong>, Ge-Peng Ji, Dingwen Zhang, Ming-Ming Cheng, Huazhu Fu, Jianbing Shen
					  	</span>
						<br />
						<span class="paper-publication">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2022</span>  
						<br />
						<span class="paper-publication">
							[CCF-A/SCI-1 Journal, IF=23.6, <span class="paper-highlight">ESI Highly Cited Paper (1%)</span>]
						</span>
						<br />
						<a href="https://arxiv.org/pdf/2007.03380" target="_blank">[PDF]</a>
						<a href="https://github.com/DengPingFan/CoEGNet" target="_blank">[Code]</a>
						<a href="./material/paper/22_TPAMI_CoEGNet_BibTeX.txt" target="_blank">[BibTeX]</a>
						<a href="https://ieeexplore.ieee.org/document/9358006" target="_blank">[Official]</a>
						<a href="https://dengpingfan.github.io/papers/[2021][TPAMI]CoSOD3k_Chinese.pdf" target="_blank">[中译版]</a>
					</div>
				</div>	
				
				<!-- 21_TIP_BiANet -->
				<div class="row paper-item" id="21_TIP_BiANet">
					<div class="col-md-3 paper-cover">
						<img src="./material/paper/21_TIP_BiANet_Cover.jpg" class="img-responsive img-thumbnail"/>
					</div>
					<div class="col-md-9 paper-info">
						<span class="paper-title">
							Bilateral Attention Network for RGB-D Salient Object Detection
						</span>
						<br />
						<span class="paper-author">
							Zhao Zhang, <strong class="text-info">Zheng Lin</strong>, Jun Xu, Wenda Jin, Shao-Ping Lu, and Deng-Ping Fan
					  	</span>
						<br />
						<span class="paper-publication">IEEE Transactions on Image Processing (TIP), 2021</span>  
						<br />
						<span class="paper-publication">
							[CCF-A/SCI-1 Journal, IF=11.041, <span class="paper-highlight">ESI Highly Cited Paper (1%)</span>]
						</span>
						<br />
						<a href="https://arxiv.org/pdf/2004.14582" target="_blank">[PDF]</a>
						<a href="https://github.com/zzhanghub/bianet" target="_blank">[Code]</a>
						<a href="./material/paper/21_TIP_BiANet_BibTeX.txt" target="_blank">[BibTeX]</a>
						<a href="https://ieeexplore.ieee.org/document/9321705" target="_blank">[Official]</a>
					</div>
				</div>	
				
				<!-- 21_TIP_SGNet -->
				<div class="row paper-item" id="21_TIP_SGNet">
					<div class="col-md-3 paper-cover">
						<img src="./material/paper/21_TIP_SGNet_Cover.jpg" class="img-responsive img-thumbnail"/>
					</div>
					<div class="col-md-9 paper-info">
						<span class="paper-title">
							Spatial Information Guided Convolution for Real-Time RGBD Semantic Segmentation
						</span>
						<br />
						<span class="paper-author">
							Lin-Zhuo Chen, <strong class="text-info">Zheng Lin</strong>, Ziqin Wang, Yong-Liang Yang, Ming-Ming Cheng
					  	</span>
						<br />
						<span class="paper-publication">IEEE Transactions on Image Processing (TIP), 2021</span> 
						<br />
						<span class="paper-publication">[CCF-A/SCI-1 Journal, IF=11.041]</span>
						<br />
						<a href="https://arxiv.org/pdf/2004.04534" target="_blank">[PDF]</a>
						<a href="https://github.com/LinZhuoChen/SGNet" target="_blank">[Code]</a>
						<a href="./material/paper/21_TIP_SGNet_BibTeX.txt" target="_blank">[BibTeX]</a>
						<a href="https://ieeexplore.ieee.org/document/9334408" target="_blank">[Official]</a>
						<a href="https://mftp.mmcheng.net/Papers/20TIP_SGNet_RGBD_Seg-cn.pdf" target="_blank">[中译版]</a>
					</div>
				</div>	
				
				<!-- 21_TNNLS_D3Net -->
				<div class="row paper-item" id="21_TNNLS_D3Net">
					<div class="col-md-3 paper-cover">
						<img src="./material/paper/21_TNNLS_D3Net_Cover.jpg" class="img-responsive img-thumbnail"/>
					</div>
					<div class="col-md-9 paper-info">
						<span class="paper-title">
							Rethinking RGB-D Salient Object Detection: Models, Data Sets, and Large-Scale Benchmarks
						</span>
						<br />
						<span class="paper-author">
							Deng-Ping Fan, <strong class="text-info">Zheng Lin</strong>, Zhao Zhang, Menglong Zhu, Ming-Ming Cheng
					  	</span>
						<br />
						<span class="paper-publication">IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2021</span>  
						<br />
						<span class="paper-publication">
							[CCF-B/SCI-1 Journal, IF=14.255, <span class="paper-highlight">ESI Hot Paper (0.1%)</span>, <span class="paper-highlight">ESI Highly Cited Paper (1%)</span>]
						</span>
						<br />
						<span class="paper-publication">
							<a href="https://scholar.google.com/citations?hl=en&view_op=list_hcore&venue=LILlZnFGZh8J.2023&cstart=20">
								[Top-10 Most Cited Paper in IEEE TNNLS 2020]
							</a>
						</span>
						<br />
						<a href="https://arxiv.org/pdf/1907.06781" target="_blank">[PDF]</a>
						<a href="https://github.com/DengPingFan/D3NetBenchmark" target="_blank">[Code]</a>
						<a href="./material/paper/21_TNNLS_D3Net_BibTeX.txt" target="_blank">[BibTeX]</a>
						<a href="https://ieeexplore.ieee.org/document/9107477" target="_blank">[Official]</a>
						<a href="https://dengpingfan.github.io/papers/[2021][TNNLS]SIPBenchmark_Chinese.pdf" target="_blank">[中译版]</a>
					</div>
				</div>
					
				<!-- 20_CVPR_FCANet -->
				<div class="row paper-item" id="20_CVPR_FCANet">
					<div class="col-md-3 paper-cover">
						<img src="./material/paper/20_CVPR_FCANet_Cover.jpg" class="img-responsive img-thumbnail"/>
					</div>
					<div class="col-md-9 paper-info">
						<span class="paper-title">
							Interactive Image Segmentation with First Click Attention
						</span>
						<br />
						<span class="paper-author">
							<strong class="text-info">Zheng Lin</strong>, Zhao Zhang, Lin-Zhuo Chen, Ming-Ming Cheng, Shao-Ping Lu
					  	</span>
						<br />
						<span class="paper-publication">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020</span>  
						<br />
						<span class="paper-publication">[CCF-A Conference, Acceptance Rate=22.1%]</span>
						<br />
						<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Lin_Interactive_Image_Segmentation_With_First_Click_Attention_CVPR_2020_paper.pdf" target="_blank">[PDF]</a>
						<a href="https://github.com/frazerlin/fcanet" target="_blank">[Code]</a>
						<a href="./material/paper/20_CVPR_FCANet_BibTeX.txt" target="_blank">[BibTeX]</a>
						<a href="https://ieeexplore.ieee.org/document/9157109" target="_blank">[Official]</a>
						<a href="./material/paper/20_CVPR_FCANet_Paper_CN.pdf" target="_blank">[中译版]</a>
						<!--<a href="NA" target="_blank">[Demo]</a>-->
						<!--<a href="TBD" target="_blank">[Video]</a>-->
					</div>
				</div>
				
				<!-- 20_CVPR_CoSOD3K -->
				<div class="row paper-item" id="20_CVPR_CoSOD3K">
					<div class="col-md-3 paper-cover">
						<img src="./material/paper/20_CVPR_CoSOD3K_Cover.jpg" class="img-responsive img-thumbnail"/>
					</div>
					<div class="col-md-9 paper-info">
						<span class="paper-title">
							Taking a Deeper Look at Co-Salient Object Detection
						</span>
						<br />
						<span class="paper-author">
							Deng-Ping Fan*, <strong class="text-info">Zheng Lin*</strong>, Ge-Peng Ji, Dingwen Zhang, Huazhu Fu, Ming-Ming Cheng
					  	</span>
						<br />
						<span class="paper-publication">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020</span>  
						<br />
						<span class="paper-publication">[CCF-A Conference, Acceptance Rate=22.1%]</span>
						<br />
						<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Fan_Taking_a_Deeper_Look_at_Co-Salient_Object_Detection_CVPR_2020_paper.pdf" target="_blank">[PDF]</a>
						<a href="https://github.com/DengPingFan/CoSOD3K" target="_blank">[Code]</a>
						<a href="./material/paper/20_CVPR_CoSOD3K_BibTeX.txt" target="_blank">[BibTeX]</a>
						<a href="https://ieeexplore.ieee.org/document/9157566" target="_blank">[Official]</a>
						<a href="https://dengpingfan.github.io/papers/[2020][CVPR]CoSOD3k_Chinese.pdf" target="_blank">[中译版]</a>
						<!--<a href="TBD" target="_blank">[Video]</a>-->
					</div>
				</div>

        </section>
    </div>

		
    <footer class="py-2 bg-dark mt-4">
        <div class="container">
            <a href="https://beian.miit.gov.cn" target="_blank">
                <p class="m-0 text-center text-white">© Zheng Lin </p>
            </a>
        </div>
    </footer>

		
    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <!-- <script src="https://kit.fontawesome.com/643e792d0b.js" crossorigin="anonymous"></script> -->
    <script src="https://cdn.bootcss.com/jquery/3.2.1/jquery.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
     crossorigin="anonymous"></script>
    <script src="https://cdn.bootcss.com/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
     crossorigin="anonymous"></script>
    <script src="https://cdn.bootcss.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
     crossorigin="anonymous"></script>
</body>

</html>